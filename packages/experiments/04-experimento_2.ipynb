{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import joblib\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix , auc, precision_recall_curve, roc_auc_score, balanced_accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74411164",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gold = pd.read_csv('../../assets/gold/experimentos_finales/dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_arboles = [5, 10, 15, 20]\n",
    "metricas = [\"gini\", \"entropy\"]\n",
    "bootstrap = [True]\n",
    "max_depth = [3]\n",
    "min_samples_split= [2]\n",
    "min_samples_leaf = [1]\n",
    "max_features = ['sqrt']\n",
    "\n",
    "\n",
    "def crear_grilla(max_arboles, metricas, bootstrap, min_samples_split, min_samples_leaf, max_features):\n",
    "    parametros = {\n",
    "        'n_estimators': max_arboles,\n",
    "        'criterion': metricas,\n",
    "        'bootstrap': bootstrap,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'max_features': max_features\n",
    "    }\n",
    "    grilla = list(ParameterGrid(parametros))\n",
    "    return grilla\n",
    "\n",
    "grilla_parametros = crear_grilla(max_arboles, metricas, bootstrap,min_samples_split, min_samples_leaf, max_features)\n",
    "grilla_parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca62464",
   "metadata": {},
   "source": [
    "## Experimento 2\n",
    "\n",
    "5 iteraciones de Random forest con boost. 20% de test se elige en cada iteración.\n",
    "\n",
    "repetir 5 veces:\n",
    "\n",
    "    test_i = tomar un 20% de test al azar  (uno distinto en cada iteracion)\n",
    "    \n",
    "    x_i = realizar experimiento con boostraping (test_i )\n",
    "\n",
    "\n",
    "Se toma como promedio, el promedio de las 5 iteraciones.  El propósito es reducir varianza y salir de un test poco afortunado.  Y si es posible, mejor performance.\n",
    "el experimento 2 no devolvería las métricas de los árboles individuales del random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "importancias_resultados = []\n",
    "\n",
    "for params in grilla_parametros:\n",
    "    accuracy_scores_train = []\n",
    "    accuracy_scores_test = []\n",
    "    balanced_accuracy_scores_train = []\n",
    "    balanced_accuracy_scores_test = []\n",
    "    auc_scores_train = []\n",
    "    auc_scores_test = []\n",
    "    importancias_atributos = []\n",
    "    print(f\"Evaluando parámetros: {params}\")\n",
    "    # Repetir el proceso 5 veces para obtener diferentes splits de entrenamiento y test\n",
    "    for i in range(5):\n",
    "        # 1. Separar un 20% random como test, el random state cambia en cada iteracion, entonces da un 20% distinto en cada una\n",
    "        X_train_base, X_test, y_train_base, y_test = train_test_split(dataset_gold[dataset_gold.columns.difference(['target'])],\n",
    "                                                                        dataset_gold['target'], test_size=0.2, random_state=i,\n",
    "                                                                        stratify=dataset_gold['target'])\n",
    "        \n",
    "        modelo = RandomForestClassifier(random_state=42, **params)\n",
    "        modelo.fit(X_train_base, y_train_base)\n",
    "\n",
    "        # Guardar importancia de atributos\n",
    "        importancias = modelo.feature_importances_\n",
    "        importancias_atributos.append(importancias)\n",
    "        \n",
    "        # Predicciones de clase\n",
    "        y_train_pred = modelo.predict(X_train_base)\n",
    "        y_validation_pred = modelo.predict(X_test)\n",
    "\n",
    "        # Predicciones de probabilidad para AUC ROC (para la clase positiva)\n",
    "        y_train_proba = modelo.predict_proba(X_train_base)[:, 1]\n",
    "        y_validation_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Accuracy\n",
    "        acc_train = accuracy_score(y_train_base, y_train_pred)\n",
    "        acc_test = accuracy_score(y_test, y_validation_pred)\n",
    "        accuracy_scores_train.append(acc_train)\n",
    "        accuracy_scores_test.append(acc_test)\n",
    "\n",
    "        # Balanced Accuracy\n",
    "        bal_acc_train = balanced_accuracy_score(y_train_base, y_train_pred)\n",
    "        bal_acc_test = balanced_accuracy_score(y_test, y_validation_pred)\n",
    "        balanced_accuracy_scores_train.append(bal_acc_train)\n",
    "        balanced_accuracy_scores_test.append(bal_acc_test)\n",
    "\n",
    "        # AUC ROC\n",
    "        auc_train = roc_auc_score(y_train_base, y_train_proba)\n",
    "        auc_test = roc_auc_score(y_test, y_validation_proba)\n",
    "        auc_scores_train.append(auc_train)\n",
    "        auc_scores_test.append(auc_test)\n",
    "    \n",
    "    # Calcular promedios y desviaciones estándar\n",
    "    accuracy_train_mean = np.mean(accuracy_scores_train)\n",
    "    accuracy_test_mean = np.mean(accuracy_scores_test)\n",
    "    accuracy_train_std = np.std(accuracy_scores_train)\n",
    "    accuracy_test_std = np.std(accuracy_scores_test)\n",
    "    bal_accuracy_train_mean = np.mean(balanced_accuracy_scores_train)\n",
    "    bal_accuracy_test_mean = np.mean(balanced_accuracy_scores_test)\n",
    "    bal_accuracy_train_std = np.std(balanced_accuracy_scores_train)\n",
    "    bal_accuracy_test_std = np.std(balanced_accuracy_scores_test)\n",
    "    auc_train_mean = np.mean(auc_scores_train)\n",
    "    auc_test_mean = np.mean(auc_scores_test)\n",
    "    auc_train_std = np.std(auc_scores_train)\n",
    "    auc_test_std = np.std(auc_scores_test)\n",
    "    print(f\"Resultados para {params}:\")\n",
    "\n",
    "    resultados.append({\n",
    "        'params': params,\n",
    "        'bootstrap': params['bootstrap'],\n",
    "        'criterion': params['criterion'],\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'train_accuracy_mean': accuracy_train_mean,\n",
    "        'test_accuracy_mean': accuracy_test_mean,\n",
    "        'train_accuracy_std': accuracy_train_std,\n",
    "        'test_accuracy_std': accuracy_test_std,\n",
    "        'train_balanced_accuracy_mean': bal_accuracy_train_mean,\n",
    "        'test_balanced_accuracy_mean': bal_accuracy_test_mean,\n",
    "        'train_balanced_accuracy_std': bal_accuracy_train_std,\n",
    "        'test_balanced_accuracy_std': bal_accuracy_test_std,\n",
    "        'train_auc_mean': auc_train_mean,\n",
    "        'test_auc_mean': auc_test_mean,\n",
    "        'train_auc_std': auc_train_std,\n",
    "        'test_auc_std': auc_test_std\n",
    "    })\n",
    "\n",
    "    # Calcular importancia promedio y std\n",
    "    importancias_array = np.array(importancias_atributos)\n",
    "    importancia_media = np.mean(importancias_array, axis=0)\n",
    "    importancia_std = np.std(importancias_array, axis=0)\n",
    "\n",
    "    # Asignar nombres de columnas\n",
    "    columnas = dataset_gold.columns.difference(['target'])\n",
    "    # Crear dict plano para el DataFrame de importancias\n",
    "    importancia_flat = {\n",
    "        f\"mean_{col}\": importancia_media[idx]\n",
    "        for idx, col in enumerate(columnas)\n",
    "    }\n",
    "    importancia_flat.update({\n",
    "        f\"std_{col}\": importancia_std[idx]\n",
    "        for idx, col in enumerate(columnas)\n",
    "    })\n",
    "    importancia_flat.update(params)  # Podés incluir los hiperparámetros para referencia\n",
    "\n",
    "    importancias_resultados.append(importancia_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.DataFrame(resultados)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.to_csv('../../assets/resultados_modelos/experimento_2_v2/resultados_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c53851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importancias = pd.DataFrame(importancias_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc20555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veo las columnas que empiezan con mean\n",
    "mean_columns = [col for col in df_importancias.columns if col.startswith('mean_')]\n",
    "df_importancias[mean_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importancias.to_csv('../../assets/resultados_modelos/experimento_2_v2/importancias_atributos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_columns = [col for col in df_importancias.columns if col.startswith('mean_')]\n",
    "\n",
    "for idx, row in df_importancias.iterrows():\n",
    "    importancias = row[mean_columns]\n",
    "    columnas = [col.replace(\"mean_\", \"\") for col in mean_columns]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(columnas, importancias)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Importancia media\")\n",
    "    plt.title(f\"Importancia de atributos - Configuración #{idx}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45830cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_columns = [col for col in df_importancias.columns if col.startswith('mean_')]\n",
    "\n",
    "for idx, row in df_importancias.iterrows():\n",
    "    importancias = row[mean_columns]\n",
    "    \n",
    "    # Ordenar y quedarse con el top 20\n",
    "    top_importancias = importancias.sort_values(ascending=False).head(20)\n",
    "    columnas_top = [col.replace(\"mean_\", \"\") for col in top_importancias.index]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(columnas_top, top_importancias.values)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Importancia media\")\n",
    "    plt.title(f\"Top 20 atributos - Configuración #{idx}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../../assets/resultados_modelos/experimento_2_v2/importancia_atributos_random_forest_sin_boostrap_{idx}_top_20.png')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
