{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import joblib\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix , auc, precision_recall_curve, roc_auc_score, balanced_accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../../assets/gold/experimentos_finales/x_train.csv')\n",
    "y_train = pd.read_csv('../../assets/gold/experimentos_finales/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bcc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = pd.read_csv('../../assets/gold/experimentos_finales/x_test.csv')\n",
    "y_validation = pd.read_csv('../../assets/gold/experimentos_finales/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.dtypes.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a38b8",
   "metadata": {},
   "source": [
    "Vamos a hacer el primer experimento \"real\"\n",
    "\n",
    "Objetivo: tener el modelo base y de acá queremos mejorar.\n",
    "* Divido en TRAIN (80% de los datos) y VALIDATION (20% de los datos) respetando la distribución de la variable target: como lo hacemos una sola vez, nos arriesgamos a que la división sea mala <-- ya lo hice arriba\n",
    "\n",
    "* Entrenamos 8 modelos Random Forest SIN bootstrap usando los datos de TRAIN. Siempre dejamos altura máxima 3\n",
    "Los 8 modelos salen de probar las combinaciones:\n",
    "5, 10, 15 y 20 árboles\n",
    "\"gini\", \"entropy\"\n",
    "\n",
    "* Presento resultados con los datos de VALIDATION: veo en general los valores de AUCROC, accuracy y balance accuracy. Sin embargo, también veo la variación entre los 5, 10 y 20 árboles del Random Forest\n",
    "Hago gráfico de importancia de atributos tomando la métrica gini\n",
    "\n",
    "Se corre el riesgo que ese 20 sea mala muestra y manche el experimento 1 --> volvemos a ver si el 2 combate estos problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_arboles = [5, 10, 15, 20]\n",
    "metricas = [\"gini\", \"entropy\"]\n",
    "bootstrap = [False]\n",
    "max_depth = [3]\n",
    "min_samples_split= [2]\n",
    "min_samples_leaf = [1]\n",
    "max_features = ['sqrt']\n",
    "\n",
    "\n",
    "def crear_grilla(max_arboles, metricas, bootstrap, min_samples_split, min_samples_leaf, max_features):\n",
    "    parametros = {\n",
    "        'n_estimators': max_arboles,\n",
    "        'criterion': metricas,\n",
    "        'bootstrap': bootstrap,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'max_features': max_features\n",
    "    }\n",
    "    grilla = list(ParameterGrid(parametros))\n",
    "    return grilla\n",
    "\n",
    "grilla_parametros = crear_grilla(max_arboles, metricas, bootstrap,min_samples_split, min_samples_leaf, max_features)\n",
    "grilla_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc_entre_arboles(modelo, x, y):\n",
    "    # Lista para guardar los AUC ROC de cada árbol\n",
    "    auc_scores = []\n",
    "\n",
    "    # Iterar sobre cada árbol en el bosque\n",
    "    for arbol in modelo.estimators_:\n",
    "        proba = arbol.predict_proba(x.values)[:, 1]\n",
    "        auc = roc_auc_score(y, proba)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Convertir a numpy array para estadística\n",
    "    auc_scores = np.array(auc_scores)\n",
    "\n",
    "    # Resultados\n",
    "    return auc_scores.mean(), auc_scores.std()\n",
    "\n",
    "def accuracy_y_balance_accuracy_entre_arboles(modelo, x, y):\n",
    "    accuracy_scores = []\n",
    "    balanced_accuracy_scores = []\n",
    "\n",
    "    for arbol in modelo.estimators_:\n",
    "        pred = arbol.predict(x.values)\n",
    "        acc = accuracy_score(y, pred)\n",
    "        bal_acc = balanced_accuracy_score(y, pred)\n",
    "        \n",
    "        accuracy_scores.append(acc)\n",
    "        balanced_accuracy_scores.append(bal_acc)\n",
    "\n",
    "    # Convertir a numpy arrays\n",
    "    accuracy_scores = np.array(accuracy_scores)\n",
    "    balanced_accuracy_scores = np.array(balanced_accuracy_scores)\n",
    "\n",
    "    # Resultados\n",
    "    return accuracy_scores.mean(), accuracy_scores.std(), balanced_accuracy_scores.mean(), balanced_accuracy_scores.std()\n",
    "\n",
    "def grafico_importancia_atributos(index, modelo, x_train, graf1, graf2):\n",
    "    \"\"\"\n",
    "    Grafica la importancia de los atributos del modelo.\n",
    "    \n",
    "    Args:\n",
    "        modelo: El modelo entrenado.\n",
    "        x_train: Datos de entrenamiento.\n",
    "    \"\"\"\n",
    "    importancias = pd.Series(modelo.feature_importances_, index=x_train.columns)\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))  # ancho x alto en pulgadas\n",
    "    importancias.sort_values(ascending=False).plot(kind='bar')\n",
    "    plt.title(f\"Importancia de atributos - Random Forest {index}\")\n",
    "    plt.ylabel(\"Importancia\")\n",
    "    plt.xlabel(\"Atributos\")\n",
    "    plt.xticks(rotation=90, ha='right')  # Rotar etiquetas para mayor claridad\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(graf1)\n",
    "    plt.show()\n",
    "\n",
    "    top_n = 20\n",
    "    importancias.sort_values(ascending=False).head(top_n).plot(kind='bar')\n",
    "    plt.title(f\"Top {top_n} Importancia de Atributos - Random Forest {index}\")\n",
    "    plt.ylabel(\"Importancia\")\n",
    "    plt.xlabel(\"Atributos\")\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotar etiquetas para mayor claridad\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(graf2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad41ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para guardar resultados\n",
    "resultados = []\n",
    "\n",
    "y_para_entrenar = y_train.squeeze()\n",
    "y_validation_para_metricas = y_validation.squeeze()\n",
    "i = 0\n",
    "\n",
    "for params in grilla_parametros:\n",
    "    # Cross-validation (por ejemplo, 5 folds estratificados)\n",
    "    modelo = RandomForestClassifier(random_state=42, **params)\n",
    "\n",
    "    ##### REVISAR PARAMETROS #####\n",
    "    \n",
    "    modelo.fit(x_train, y_para_entrenar)\n",
    "\n",
    "    # Graficar la importancia de los atributos\n",
    "    grafico_importancia_atributos(i, modelo, x_train, f'../../assets/resultados_modelos/experimento_1_v2/importancia_atributos_random_forest_sin_boostrap_{i}.png', f'../../assets/resultados_modelos/experimento_1_v2/importancia_atributos_random_forest_sin_boostrap_{i}_top_20.png')\n",
    "\n",
    "    joblib.dump(modelo, f'../../assets/resultados_modelos/experimento_1_v2/random_forest_sin_boostrap_{i}.pkl')\n",
    "    print(f\"Modelo guardado {i}\")\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "    # Predicciones de clase\n",
    "    y_train_pred = modelo.predict(x_train)\n",
    "    y_validation_pred = modelo.predict(x_validation)\n",
    "\n",
    "    # Predicciones de probabilidad para AUC ROC (para la clase positiva)\n",
    "    y_train_proba = modelo.predict_proba(x_train)[:, 1]\n",
    "    y_validation_proba = modelo.predict_proba(x_validation)[:, 1]\n",
    "\n",
    "    # Accuracy\n",
    "    acc_train = accuracy_score(y_para_entrenar, y_train_pred)\n",
    "    acc_test = accuracy_score(y_validation_para_metricas, y_validation_pred)\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    bal_acc_train = balanced_accuracy_score(y_para_entrenar, y_train_pred)\n",
    "    bal_acc_test = balanced_accuracy_score(y_validation_para_metricas, y_validation_pred)\n",
    "\n",
    "    # AUC ROC\n",
    "    auc_train = roc_auc_score(y_para_entrenar, y_train_proba)\n",
    "    auc_test = roc_auc_score(y_validation_para_metricas, y_validation_proba)\n",
    "\n",
    "    \n",
    "    resultados.append({\n",
    "        'params': params,\n",
    "        'bootstrap': params['bootstrap'],\n",
    "        'criterion': params['criterion'],\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'train_accuracy': acc_train,\n",
    "        'test_accuracy': acc_test,\n",
    "        'train_balanced_accuracy': bal_acc_train,\n",
    "        'test_balanced_accuracy': bal_acc_test,\n",
    "        'train_auc': auc_train,\n",
    "        'test_auc': auc_test,\n",
    "        'mean_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train, y_train)[0],\n",
    "        'std_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train, y_train)[1],\n",
    "        'mean_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation, y_validation_para_metricas)[0],\n",
    "        'std_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation, y_validation_para_metricas)[1],\n",
    "        'mean_balanced_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation, y_validation_para_metricas)[2],\n",
    "        'std_balanced_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation, y_validation_para_metricas)[3],\n",
    "        'mean_balanced_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train, y_train)[2],\n",
    "        'std_balanced_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train, y_train)[3],\n",
    "        'mean_auc_test': auc_roc_entre_arboles(modelo, x_validation, y_validation_para_metricas)[0],\n",
    "        'std_auc_test': auc_roc_entre_arboles(modelo, x_validation, y_validation_para_metricas)[1],\n",
    "        'mean_auc_train': auc_roc_entre_arboles(modelo, x_train, y_train)[0],\n",
    "        'std_auc_train': auc_roc_entre_arboles(modelo, x_train, y_train)[1]   \n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.sort_values(by=\"test_auc\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a01c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.to_csv('../../assets/resultados_modelos/experimento_1_v2/resultados_random_forest_sin_boostrap.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb0557",
   "metadata": {},
   "source": [
    "### Parte B del experimento\n",
    "\n",
    "Quiero ver esto mismo pero sacando los datos que \"manchan\" el resto de mis resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sin_importantes = x_train.drop(columns=['finales_inscriptos_1.0', 'finales_inscriptos_2.0', 'finales_inscriptos_3.0',\n",
    "                                                'inscripciones_1.0', 'inscripciones_2.0', 'inscripciones_3.0',\n",
    "                                                'nota_final_materia_10', 'nota_final_materia_2',\n",
    "                                                'nota_final_materia_3', 'nota_final_materia_4', 'nota_final_materia_5',\n",
    "                                                'nota_final_materia_6', 'nota_final_materia_7', 'nota_final_materia_8',\n",
    "                                                'nota_final_materia_9','tp_aprobado_materia_10', 'tp_aprobado_materia_2',\n",
    "                                                'tp_aprobado_materia_3', 'tp_aprobado_materia_4',\n",
    "                                                'tp_aprobado_materia_5', 'tp_aprobado_materia_6',\n",
    "                                                'tp_aprobado_materia_7', 'tp_aprobado_materia_8',\n",
    "                                                'tp_aprobado_materia_9', 'tp_aprobado_materia_1', 'tp_aprobados_1.0',\n",
    "                                                'tp_aprobados_2.0', 'tp_aprobados_3.0', 'tp_aprobados_0.0', 'finales_inscriptos_0.0', 'inscripciones_0.0', 'nota_final_materia_1'])\n",
    "x_validation_sin_importantes = x_validation.drop(columns=['finales_inscriptos_1.0', 'finales_inscriptos_2.0', 'finales_inscriptos_3.0',\n",
    "                                                'inscripciones_1.0', 'inscripciones_2.0', 'inscripciones_3.0',\n",
    "                                                'nota_final_materia_10', 'nota_final_materia_2',\n",
    "                                                'nota_final_materia_3', 'nota_final_materia_4', 'nota_final_materia_5',\n",
    "                                                'nota_final_materia_6', 'nota_final_materia_7', 'nota_final_materia_8',\n",
    "                                                'nota_final_materia_9','tp_aprobado_materia_10', 'tp_aprobado_materia_2',\n",
    "                                                'tp_aprobado_materia_3', 'tp_aprobado_materia_4',\n",
    "                                                'tp_aprobado_materia_5', 'tp_aprobado_materia_6',\n",
    "                                                'tp_aprobado_materia_7', 'tp_aprobado_materia_8',\n",
    "                                                'tp_aprobado_materia_9','tp_aprobado_materia_1','tp_aprobados_1.0',\n",
    "                                                'tp_aprobados_2.0', 'tp_aprobados_3.0', 'tp_aprobados_0.0', 'finales_inscriptos_0.0', 'inscripciones_0.0', 'nota_final_materia_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0517653",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sin_importantes.columns[~x_train_sin_importantes.columns.isin(x_validation_sin_importantes.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation_sin_importantes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5093a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para guardar resultados\n",
    "resultados = []\n",
    "\n",
    "y_para_entrenar = y_train.squeeze()\n",
    "y_validation_para_metricas = y_validation.squeeze()\n",
    "i = 0\n",
    "\n",
    "for params in grilla_parametros:\n",
    "    # Cross-validation (por ejemplo, 5 folds estratificados)\n",
    "    modelo = RandomForestClassifier(random_state=42, **params)\n",
    "\n",
    "    ##### REVISAR PARAMETROS #####\n",
    "    \n",
    "    modelo.fit(x_train_sin_importantes, y_para_entrenar)\n",
    "\n",
    "    # Graficar la importancia de los atributos\n",
    "    grafico_importancia_atributos(i, modelo, x_train_sin_importantes, f'../../assets/resultados_modelos/experimento_1_b_solo_fechas/importancia_atributos_random_forest_sin_boostrap_{i}.png', f'../../assets/resultados_modelos/experimento_1_b_solo_fechas/importancia_atributos_random_forest_sin_boostrap_{i}_top_20.png')\n",
    "\n",
    "    joblib.dump(modelo, f'../../assets/resultados_modelos/experimento_1_b_solo_fechas/random_forest_sin_boostrap_{i}.pkl')\n",
    "    print(f\"Modelo guardado {i}\")\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "    # Predicciones de clase\n",
    "    y_train_pred = modelo.predict(x_train_sin_importantes)\n",
    "    y_validation_pred = modelo.predict(x_validation_sin_importantes)\n",
    "\n",
    "    # Predicciones de probabilidad para AUC ROC (para la clase positiva)\n",
    "    y_train_proba = modelo.predict_proba(x_train_sin_importantes)[:, 1]\n",
    "    y_validation_proba = modelo.predict_proba(x_validation_sin_importantes)[:, 1]\n",
    "\n",
    "    # Accuracy\n",
    "    acc_train = accuracy_score(y_para_entrenar, y_train_pred)\n",
    "    acc_test = accuracy_score(y_validation_para_metricas, y_validation_pred)\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    bal_acc_train = balanced_accuracy_score(y_para_entrenar, y_train_pred)\n",
    "    bal_acc_test = balanced_accuracy_score(y_validation_para_metricas, y_validation_pred)\n",
    "\n",
    "    # AUC ROC\n",
    "    auc_train = roc_auc_score(y_para_entrenar, y_train_proba)\n",
    "    auc_test = roc_auc_score(y_validation_para_metricas, y_validation_proba)\n",
    "\n",
    "    \n",
    "    resultados.append({\n",
    "        'params': params,\n",
    "        'bootstrap': params['bootstrap'],\n",
    "        'criterion': params['criterion'],\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'train_accuracy': acc_train,\n",
    "        'test_accuracy': acc_test,\n",
    "        'train_balanced_accuracy': bal_acc_train,\n",
    "        'test_balanced_accuracy': bal_acc_test,\n",
    "        'train_auc': auc_train,\n",
    "        'test_auc': auc_test,\n",
    "        'mean_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train_sin_importantes, y_train)[0],\n",
    "        'std_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train_sin_importantes, y_train)[1],\n",
    "        'mean_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation_sin_importantes, y_validation_para_metricas)[0],\n",
    "        'std_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation_sin_importantes, y_validation_para_metricas)[1],\n",
    "        'mean_balanced_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation_sin_importantes, y_validation_para_metricas)[2],\n",
    "        'std_balanced_accuracy_test': accuracy_y_balance_accuracy_entre_arboles(modelo, x_validation_sin_importantes, y_validation_para_metricas)[3],\n",
    "        'mean_balanced_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train_sin_importantes, y_train)[2],\n",
    "        'std_balanced_accuracy_train': accuracy_y_balance_accuracy_entre_arboles(modelo, x_train_sin_importantes, y_train)[3],\n",
    "        'mean_auc_test': auc_roc_entre_arboles(modelo, x_validation_sin_importantes, y_validation_para_metricas)[0],\n",
    "        'std_auc_test': auc_roc_entre_arboles(modelo, x_validation_sin_importantes, y_validation_para_metricas)[1],\n",
    "        'mean_auc_train': auc_roc_entre_arboles(modelo, x_train_sin_importantes, y_train)[0],\n",
    "        'std_auc_train': auc_roc_entre_arboles(modelo, x_train_sin_importantes, y_train)[1]   \n",
    "    })\n",
    "\n",
    "df_resultados_b = pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e596dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_b.to_csv('../../assets/resultados_modelos/experimento_1_b_solo_fechas/resultados_random_forest_sin_boostrap_sin_importantes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
